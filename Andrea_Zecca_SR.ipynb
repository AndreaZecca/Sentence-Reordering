{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"ElNaMbLnRdHR"},"source":["# Sentence Reconstruction"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oXr4iGUGRms8"},"source":["The purpose of this project is to take in input a sequence of words corresponding to a random permutation of a given english sentence, and reconstruct the original sentence. \n","\n","The otuput can be either produced in a single shot, or through an iterative (autoregressive) loop generating a single token at a time.\n","\n","CONSTRAINTS:\n","* No pretrained model can be used.\n","* The neural network models should have less the 20M parameters.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"iQ8k-L-WUK7l"},"source":["# Dataset\n","\n","The dataset is composed by a snapshot of wikipedia. We restricted the vocabolary to the 10K most frequent words, and only took sentences making use of this vocabulary. In addition, we restricted to sequences with a length between 3 and 30 words.\n","\n","(Ignore the error, if any) "]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53483,"status":"ok","timestamp":1686377330120,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"0xmXLLfaUKA6","outputId":"7e00832e-04ab-4915-ff94-8ee42a712bd6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.7,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n","Collecting aiohttp (from datasets)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0 (from datasets)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Collecting responses<0.19 (from datasets)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.15.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting apache-beam\n","  Downloading apache_beam-2.48.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting crcmod<2.0,>=1.7 (from apache-beam)\n","  Downloading crcmod-1.7.tar.gz (89 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting orjson<4.0 (from apache-beam)\n","  Downloading orjson-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam)\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2.2.1)\n","Collecting fastavro<2,>=0.23.6 (from apache-beam)\n","  Downloading fastavro-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fasteners<1.0,>=0.3 (from apache-beam)\n","  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n","Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (1.54.0)\n","Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam)\n","  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n","Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (0.21.0)\n","Requirement already satisfied: numpy<1.25.0,>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (1.22.4)\n","Collecting objsize<0.7.0,>=0.6.1 (from apache-beam)\n","  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n","Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam)\n","  Downloading pymongo-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (1.22.2)\n","Requirement already satisfied: protobuf<4.24.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (3.20.3)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (1.4.2)\n","Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2.8.2)\n","Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2022.7.1)\n","Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2022.10.31)\n","Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2.27.1)\n","Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (4.5.0)\n","Collecting zstandard<1,>=0.18.0 (from apache-beam)\n","  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (9.0.0)\n","Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam)\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam) (1.16.0)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam) (3.0.9)\n","Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam)\n","  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (3.4)\n","Building wheels for collected packages: crcmod, dill, docopt\n","  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=37104 sha256=a0a30d2dfa5267bcb1ca1dd600b5df5e6676fe874bb2b38ee4c6d60c7c2135e5\n","  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78545 sha256=aa55ff22eea18eef3280170ed6c79d016c82a2e4c4731ca6bc42ff2e0a30a3dd\n","  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=7b91e773149d2a5d8d54a63d340b77e88ffb28d5d33aca5f7a2c13a44d64ffcb\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","Successfully built crcmod dill docopt\n","Installing collected packages: docopt, crcmod, zstandard, orjson, objsize, fasteners, fastavro, dnspython, dill, pymongo, hdfs, apache-beam\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.6\n","    Uninstalling dill-0.3.6:\n","      Successfully uninstalled dill-0.3.6\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.14 requires dill>=0.3.6, but you have dill 0.3.1.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed apache-beam-2.48.0 crcmod-1.7 dill-0.3.1.1 dnspython-2.3.0 docopt-0.6.2 fastavro-1.7.4 fasteners-0.18 hdfs-2.7.0 objsize-0.6.1 orjson-3.9.1 pymongo-4.3.3 zstandard-0.21.0\n"]}],"source":["!pip install datasets\n","!pip3 install apache-beam"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1686377330120,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"INZIMG8itLHh"},"outputs":[],"source":["from random import Random\n","\n","# Instantiate the Random instance with random seed = 42 to ensure reproducibility\n","randomizer = Random(42)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2929,"status":"ok","timestamp":1686377333044,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"jRVmQCKdRb54"},"outputs":[],"source":["from keras.preprocessing.text import Tokenizer\n","from keras.utils import to_categorical, pad_sequences\n","import numpy as np \n","import pickle\n","import gdown\n","import random"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264,"referenced_widgets":["a817346052c04deda9270436aa0f0cda","0b6d89eac3f14569950292ed7e84e48c","4511e8136b4b4f389a40eb6894db5aa7","749f1e44cc3b41f5b2e1d1672c9d4e41","a9e38c3233cc4d0b8b4017c327595c28","30ed19096ea242d9928be0665def9670","57f1cb96a5f54339a275670023c6e92d","953645a5b0d34ccf926be03c50b6262f","6a59f109308e49a9afafb323119709ef","41609760d6d6450bbf8dfc9121550ed4","6e6043451c4b468db3307ff6ef9f65c8","f1945a721f604cc98a8ab4e71433eaf7","7d0864a18b5843b68d28e356fc8f3b5b","20cf001596f34745ab0a763d1db26f1a","746d93750bb5448395301b983134ab8c","b4c61049b41743cc858ea45b0ad16dd4","b64b30bac1244c91af3abaa5bf6c2067","5a03da2908bc459797107ff07227cf8c","af4faa8f35a04b06bf9177dc1889e46e","96fa2fdaa2634d189f2f97dd3dc37a0d","12c42fce406d48179c57e67d331b38f7","bc3a369fe78448c7a812c2e676fb06a3","0855789e6e6d4b46ab772ab0981f6d27","0949f68ed2914f3a934c2b752efe2a33","6fd097d02ffb41e9892818b3251d79b1","2037c9446fe44ec2a0a75a07569a92d1","f28ed15278c34410b9454befa2ab5f62","4b23800862544f9b8134a9c8227bb9d8","dc23efc0a8764f92b53b0c234e59dc73","4ce528d014044eb98dd8e2dba47b1918","f864cbb46b6d4b9799b9c11ba16f6148","84cd5c474c5e4d328b532bb8afb23a85","9a3e08fb71784ff499a8d7681f160856","d3d35d3ce0e042c3ac6bafe5e3ff9bc9","705324651e2d4ae88a16f24fe75ac899","c5344ad20fd145129a6bbd115b598548","c92e80687cca4e57a89371ebbe8d1a1a","69ad765cca0b416ea2ab0edb7947e187","fc81cf6b330047b9b9a723ebcb6cc46e","36b0b74f1f654d6ba951bc8c90fd7c57","e8f24ddcad8c4616a1dd360d409995c1","bff22b2d0d1c434499172a2ded4b92be","8b8d8bb07a8444bbac5b1246059081c3","fa170c1739a847248244312e8b23ce17","cdb5a1c0ed904c4fba2f64d40b01eb95","78c5a4067d72485b928f6ce8903cb202","4abb98faa57045e6aefbc3674e946140","0cf43eb9a66b4947875f6fa2d048100d","8be8dc909cd34ffcb0bca7189b101dc5","b5bc45709da943b0864c91355286338d","d6aea1313eb748da8ca524235a011ade","78f2a39ddab249ec9c768b75eb0d2547","a0a2b843bdb14e76b5a70095ea223d35","7c42aca30a614aea988d97d526772966","e69251f8823142deb4185d0b8ace1a69","832ac4efd07f4f42b4ca56562ccecd6a","51964e8edcb94726b83557bf3b6903c6","e92e21a59fff4f3caaf1102f95c03817","9ba9053ed4c5419aa766ca75096a1bb2","93465bf04b7d4119a73a2b12f45e458f","26678d02176a483e883ce7f5b067b566","1b6b2c708f6942b2b4fff7ba98710fda","1f9f80af770b452ab24da31b0f965f65","9e18ae6aba9a42a49874bdce6bb00455","d8ea82a0e64441218fbb7f72b801a8b0","8516b34b01df4fceaa7f378e382f43ee"]},"executionInfo":{"elapsed":12246,"status":"ok","timestamp":1686377345286,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"AoeyVDv9uDwx","outputId":"77bc0f8d-c860-4604-8ca0-62476a3499eb"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a817346052c04deda9270436aa0f0cda","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/35.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f1945a721f604cc98a8ab4e71433eaf7","version_major":2,"version_minor":0},"text/plain":["Downloading metadata:   0%|          | 0.00/30.4k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0855789e6e6d4b46ab772ab0981f6d27","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/16.3k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset wikipedia/20220301.simple to /root/.cache/huggingface/datasets/wikipedia/20220301.simple/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3d35d3ce0e042c3ac6bafe5e3ff9bc9","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.66k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cdb5a1c0ed904c4fba2f64d40b01eb95","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/235M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset wikipedia downloaded and prepared to /root/.cache/huggingface/datasets/wikipedia/20220301.simple/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"832ac4efd07f4f42b4ca56562ccecd6a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"wikipedia\", \"20220301.simple\")\n","\n","data = dataset['train'][:20000]['text']"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41513,"status":"ok","timestamp":1686377386772,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"OzcYlWm8trh9","outputId":"bdead57e-45b0-4730-822b-5497edd5dc1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["corpus dim:  510023\n","filtered sentences:  137301\n"]}],"source":["#run this cell only the first time to create and save the tokenizer and the date\n","dump = False\n","\n","tokenizer = Tokenizer(split=' ', filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', num_words=10000, oov_token='<unk>')\n","\n","corpus = []\n","\n","# Split of each piece of text into sentences\n","for elem in data:\n","  corpus += elem.lower().replace(\"\\n\", \"\").split(\".\")[:]\n","\n","print(\"corpus dim: \",len(corpus))\n","\n","#add a start and an end token\n","corpus = ['<start> '+s+' <end>' for s in corpus]\n","\n","# Tokenization\t\n","tokenizer.fit_on_texts(corpus)\n","\n","if dump:\n","    with open('tokenizer.pickle', 'wb') as handle:\n","        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","original_data = [sen for sen in tokenizer.texts_to_sequences(corpus) if (len(sen) <= 32 and len(sen)>4 and not(1 in sen))]\n","\n","if dump:\n","    with open('original.pickle', 'wb') as handle:\n","        pickle.dump(original_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","print (\"filtered sentences: \",len(original_data))\n","\n","sos = tokenizer.word_index['<start>']\n","eos = tokenizer.word_index['<end>']\n","\n","tokenizer.word_index['<pad>'] = 0\n","tokenizer.index_word[0] = '<pad>'"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"K1woGS7a4Ez4"},"source":["We now create two additional datasets. \n","* shuffled_data contains scrumbled sequences, and will be the input to the model. \n","* target_data is the same as original data but offset by one timestep.\n","It is only useful if you plan to do some language modeling with a teacher forcing technique. You might decide to ignore it.\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2528,"status":"ok","timestamp":1686377389297,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"rs4cerfa4D15"},"outputs":[],"source":["shuffled_data = [random.sample(s[1:-1],len(s)-2) for s in original_data]\n","shuffled_data = [[sos]+s+[eos] for s in shuffled_data]\n","target_data = [s[1:] for s in original_data]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mGNwATns6hQ0"},"source":["Let us look at some examples:"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1686377389298,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"ChbvR6ue6lpj","outputId":"51116492-8ecd-4402-f167-326d5646eb71"},"outputs":[{"name":"stdout","output_type":"stream","text":["original sentence:  [2, 4, 43, 113, 9, 299, 628, 645, 6, 98, 114, 2425, 3]\n","shuffled sentecen:  [2, 98, 114, 299, 628, 645, 9, 4, 2425, 113, 43, 6, 3]\n"]}],"source":["i = np.random.randint(len(original_data))\n","print(\"original sentence: \",original_data[i])\n","print(\"shuffled sentecen: \",shuffled_data[i])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"er0FoTdc8sLq"},"source":["Let us look at detokenized data:"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1686377389299,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"OMKM9B1w8yWX","outputId":"4656a65a-ce1d-47e2-8883-32175006f46a"},"outputs":[{"name":"stdout","output_type":"stream","text":["original sentence:  <start> the first player to go cannot move and so will lose <end>\n","shuffled sentence:  <start> so will go cannot move to the lose player first and <end>\n"]}],"source":["# i = np.random.randint(len(original_data))\n","print(\"original sentence: \",tokenizer.sequences_to_texts([original_data[i]])[0])\n","print(\"shuffled sentence: \",tokenizer.sequences_to_texts([shuffled_data[i]])[0])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Kja87gEg9Rje"},"source":["You goal is to reconstruct the original sentence out of the shuffled one."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"s6pe2f8h9gmG"},"source":["# Additional material"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"EA6su74d9o7v"},"source":["Here we provide a few additional functions that could be useful to you."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"MhD75oyt-AO8"},"source":["As usual, you are supposed to divide your data in training and test set. Reserve at least 30% of data for testing.\n","\n","You are likely to need a validation set too."]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":675,"status":"ok","timestamp":1686377389956,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"dIDuV_Sj9oZo"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, c_train, c_test, y_train, y_test = train_test_split(original_data, shuffled_data, target_data, test_size = 0.3, random_state = 42)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8xVOHLBvMuFP"},"source":["# Data Augmentation\n","Since transformers perform better when using large datasets, it's better to apply some data augmentation techniques.\n","\n","In particular:\n","1.   Using the remaining part of the wikipedia dataset provide lots of useful data\n","2.   Splitting longer sentences into two smaller sub-sentences could help the transformers in dealing with the reconstruction of longest ones \n","\n","This kind of techniques aim to collect more data for the training phase, without modifying both the test set and the tokenizer."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44361,"status":"ok","timestamp":1686377451663,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"n5WRM5H-WO11","outputId":"69ccb253-1d48-4c6a-dd93-67cc4c98fec6"},"outputs":[{"name":"stdout","output_type":"stream","text":["corpus dim:  1813443\n"]}],"source":["# Using the other part of the wikipedia dataset in order to collect as much data as possible\n","# Performing this operation won't change the test set and won't change the tokenizer  \n","data2 = dataset['train'][20000:]['text']\n","\n","corpus2 = []\n","\n","# Split of each piece of text into sentences\n","for elem in data2:\n","    corpus2 += elem.lower().replace(\"\\n\", \"\").split(\".\")[:]\n","\n","print(\"corpus dim: \",len(corpus2))\n","\n","#add a start and an end token\n","corpus2 = ['<start> '+s+' <end>' for s in corpus2]\n","\n","original_data2 = [sen for sen in tokenizer.texts_to_sequences(corpus2) if (len(sen) <= 32 and len(sen)>4 and not(1 in sen))]"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":6468,"status":"ok","timestamp":1686377468865,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"0MA0ZvEfXnWP"},"outputs":[],"source":["shuffled_data2 = [random.sample(s[1:-1], len(s) - 2) for s in original_data2]\n","shuffled_data2 = [[sos] + s + [eos] for s in shuffled_data2]\n","target_data2 = [s[1:] for s in original_data2]"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":302,"status":"ok","timestamp":1686377473658,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"o2bmpg9dYRiu","outputId":"f8050492-5ccc-4c5c-ee50-cfaef9e9fafd"},"outputs":[{"data":{"text/plain":["[2, 4, 827, 5, 4, 3384, 2856, 19, 37, 163, 4, 1024, 10, 8901, 3]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["original_data2[0]"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1686377475610,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"aNgWd3bhX8nt"},"outputs":[],"source":["x_train += original_data2\n","c_train += shuffled_data2\n","y_train += target_data2"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":3911,"status":"ok","timestamp":1686378429172,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"m6sziIla7jaH"},"outputs":[],"source":["# data augmentation 2\n","# Take all the sentences whose len is >= 16 and divide them in 2 sub-sentences\n","# This should help the transformer to deal with large sentences, learning how to reconstruct them\n","actual_len = len(x_train)\n","for i in range(actual_len):\n","    x_sen = x_train[i]\n","    x_sen = x_sen[1:-1]\n","    if len(x_sen) >= 16:  \n","        # Only take sentences longer than 16 words (excluding sos and eos) and split them in the middle\n","        middle_sentence = len(x_sen) // 2\n","        \n","        # first and second subpart of the sentence, which will be added as new data in x_train after adding sos and eos\n","        first_subpart = x_sen[:middle_sentence]\n","        second_subpart = x_sen[middle_sentence:]\n","        \n","        # first and second subpart but shuffled, which will be added as new data in c_train after adding sos and eos\n","        first_subpart_shuffled = random.sample(first_subpart, len(first_subpart))\n","        second_subpart_shuffled = random.sample(second_subpart, len(second_subpart))\n","\n","        # adding sos and eos\n","        first_subpart_shuffled = [sos] + first_subpart_shuffled + [eos]\n","        second_subpart_shuffled = [sos] + second_subpart_shuffled + [eos]\n","\n","        first_subpart = [sos] + first_subpart + [eos]\n","        second_subpart = [sos] + second_subpart + [eos]\n","\n","        # appending on x_train\n","        x_train.append(first_subpart)\n","        x_train.append(second_subpart)\n","        \n","        # appending on c_train\n","        c_train.append(first_subpart_shuffled)\n","        c_train.append(second_subpart_shuffled)\n","        \n","        # in y_train adding the first and second subpart but shifted by one timestamp\n","        y_train.append(first_subpart[1:])\n","        y_train.append(second_subpart[1:])   \n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eOjaBx8d-lEw"},"source":["Depending from the model you plan to build, you might require padding the input sequence"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":7278,"status":"ok","timestamp":1686378442580,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"cbZ1tSFN-kWj"},"outputs":[],"source":["max_sequence_len = max([len(x) for x in original_data])\n","\n","x_train = pad_sequences(x_train, maxlen=max_sequence_len, padding='post')\n","x_test = pad_sequences(x_test, maxlen=max_sequence_len, padding='post')\n","c_train = pad_sequences(c_train, maxlen=max_sequence_len, padding='post')\n","c_test = pad_sequences(c_test, maxlen=max_sequence_len, padding='post')\n","y_train = pad_sequences(y_train, maxlen=max_sequence_len, padding='post')\n","y_test = pad_sequences(y_test, maxlen=max_sequence_len, padding='post')"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":615,"status":"ok","timestamp":1686378449744,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"2PVzEwm8-8Yj","outputId":"a76104f0-a8e9-42c9-f325-a910b97a22e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["x_train size: 641818\n"]}],"source":["print(\"x_train size:\", len(x_train))\n","assert(len(x_train)==len(c_train)==len(y_train))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4jrATEiF_mMo"},"source":["Let us finally have a look at the distribution of data w.r.t. their lenght."]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":569},"executionInfo":{"elapsed":3764,"status":"ok","timestamp":1686378484256,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"KmzOMET9_jxp","outputId":"44e662b1-1e77-4ff2-ce60-6ee102255f19"},"outputs":[{"data":{"text/plain":["(array([ 3897.,  5516.,  6180.,  7633., 10474., 11260., 11167., 10501.,\n","         9768.,  8942.,  7828.,  7010.,  6126.,  5236.,  4551.,  3922.,\n","         3260.,  2695.,  2306.,  1922.,  1611.,  1299.,  1126.,   827.,\n","          773.,   586.,   885.]),\n"," array([ 3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15.,\n","        16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28.,\n","        29., 30.]),\n"," <BarContainer object of 27 artists>)"]},"execution_count":46,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","plt.hist([len(x)-2 for x in original_data],27)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Fo8MazCGBTv3"},"source":["# Metrics"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"G0NOkuO0CfPo"},"source":["Let s be the source string and p your prediction. The quality of the results will be measured according to the following metric:\n","\n","1.  look for the longest substring w between s and p\n","2.  compute |w|/|s|\n","\n","If the match is exact, the score is 1. \n","\n","When computing the score, you should NON consider the start and end tokens.\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"a-aUrdlXDdVf"},"source":["The longest common substring can be computed with the SequenceMatcher function of difflib, that allows a simple definition of our metric."]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":585,"status":"ok","timestamp":1686378491729,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"ulpTRdrF_huh"},"outputs":[],"source":["from difflib import SequenceMatcher\n","\n","def score(s,p):\n","  match = SequenceMatcher(None, s, p).find_longest_match()\n","  #print(match.size)\n","  # modified scoring funciton (division by the max len between the two strings)\n","  return (match.size/max(len(s),len(p)))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RB2YfjXNExM-"},"source":["Let's do an example."]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1686378493573,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"h17C8bVjEwur","outputId":"c9105ca1-2bf3-41b7-baab-702a5b2ad3d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["your score is  0.5423728813559322\n"]}],"source":["original = \"at first henry wanted to be friends with the king of france\"\n","generated = \"henry wanted to be friends with king of france at the first\"\n","\n","print(\"your score is \",score(original,generated))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BET8GqBvFugR"},"source":["The score must be computed as an average of at least 3K random examples taken form the test set."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4fwo7xj4GBW1"},"source":["# What to deliver"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"i6uITuxOGHfJ"},"source":["You are supposed to deliver a single notebook, suitably commented. \n","The notebook should describe a single model, although you may briefly discuss additional attempts you did.\n","\n","The notebook should contain a full trace of the training. \n","Weights should be made available on request.\n","\n","You must also give a clear assesment of the performance of the model, computed with the metric that has been given to you.\n","\n","# Good work!"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1686378495549,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"FaLPG8CLuV85"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import keras.backend as k"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RF8TvwizNvqU"},"source":["# Model\n","Both the transformer and the learning rate schedule are taken from the [tensorflow example](https://www.tensorflow.org/text/tutorials/transformer) on transformers. \n","\n","The following changes have been made:\n","*   Single embedder for both encoder and decoder\n","*   Removed positional embedding in the encoder since the indexes of the word in the input sentences are not relevant, because they are shuffled sentences\n","\n","Digression on other models:\n","\n","Other approaches have been tried:\n","* Simple LSTM\n","* Bidirectional LSTM\n","* LSTM with a sort of attention mechanism\n","* Bidirectional LSTM with a sort of attention mechanism\n","\n","but none of them was able to achieve a good score."]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1686378504148,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"F1VvJjAnuV88"},"outputs":[],"source":["# positional encoding uses a set of sines and cosines at different frequencies\n","# so nearby elements will have similar position encodings\n","def positional_encoding(length, depth):\n","    depth = depth/2\n","    \n","    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n","    depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n","\n","    angle_rates = 1 / (10000**depths)         # (1, depth)\n","    angle_rads = positions * angle_rates      # (pos, depth)\n","\n","    pos_encoding = np.concatenate(\n","        [np.sin(angle_rads), np.cos(angle_rads)],\n","        axis=-1) \n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1686378504149,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"G0KK7ZYpuV89"},"outputs":[],"source":["# the Positional Embedding look's up a token's embedding vector and adds the position vector\n","class PositionalEmbedding(tf.keras.layers.Layer):\n","    def __init__(self, embedder, vocab_size, d_model):\n","        super().__init__()\n","        self.d_model = d_model\n","        self.embedding = embedder#tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n","        self.pos_encoding = positional_encoding(length=32, depth=d_model)\n","    def compute_mask(self, *args, **kwargs):\n","        return self.embedding.compute_mask(*args, **kwargs)\n","    def call(self, x):\n","        length = tf.shape(x)[1]\n","        x = self.embedding(x)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[tf.newaxis, :length, :]\n","        return x"]},{"cell_type":"code","execution_count":52,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1686378505966,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"zp3RdA2nuV8-"},"outputs":[],"source":["# to deal with attention it's better to define a base class which contains the component layers\n","class BaseAttention(tf.keras.layers.Layer):\n","    def __init__(self, **kwargs):\n","        super().__init__()\n","        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n","        self.layernorm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.add = tf.keras.layers.Add()"]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1686378507835,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"FrzFK3-guV9A"},"outputs":[],"source":["class CrossAttention(BaseAttention):\n","    def call(self, x, context):\n","        attn_output, att_scores = self.mha(\n","            query=x,\n","            key=context,\n","            value=context,\n","            return_attention_scores=True\n","        )\n","        self.last_attn_scores = att_scores\n","\n","        x = self.add([x, attn_output])\n","        x = self.layernorm(x)\n","        return x"]},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1686378509513,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"8fD7q5lGuV9f"},"outputs":[],"source":["class GlobalSelfAttention(BaseAttention):\n","    def call(self, x):\n","        attn_output = self.mha(\n","            query=x,\n","            value=x,\n","            key=x\n","        )\n","        x = self.add([x, attn_output])\n","        x = self.layernorm(x)\n","        return x"]},{"cell_type":"code","execution_count":55,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1686378510690,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"zlc3UCj7uV9h"},"outputs":[],"source":["class CausalSelfAttention(BaseAttention):\n","  def call(self, x):\n","    attn_output = self.mha(\n","        query=x,\n","        value=x,\n","        key=x,\n","        use_causal_mask = True)\n","    x = self.add([x, attn_output])\n","    x = self.layernorm(x)\n","    return x"]},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1686378511090,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"-7TBjDzAuV9i"},"outputs":[],"source":["class FeedForward(tf.keras.layers.Layer):\n","  def __init__(self, d_model, dff, dropout_rate=0.1):\n","    super().__init__()\n","    self.seq = tf.keras.Sequential([\n","      tf.keras.layers.Dense(dff, activation='relu'),\n","      tf.keras.layers.Dense(d_model),\n","      tf.keras.layers.Dropout(dropout_rate)\n","    ])\n","    self.add = tf.keras.layers.Add()\n","    self.layer_norm = tf.keras.layers.LayerNormalization()\n","\n","  def call(self, x):\n","    x = self.add([x, self.seq(x)])\n","    x = self.layer_norm(x) \n","    return x"]},{"cell_type":"code","execution_count":57,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1686378512846,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"KyDEcBm2uV9j"},"outputs":[],"source":["class EncoderLayer(tf.keras.layers.Layer):\n","  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n","    super().__init__()\n","\n","    self.self_attention = GlobalSelfAttention(\n","        num_heads=num_heads,\n","        key_dim=d_model,\n","        dropout=dropout_rate)\n","\n","    self.ffn = FeedForward(d_model, dff)\n","\n","  def call(self, x):\n","    x = self.self_attention(x)\n","    x = self.ffn(x)\n","    return x"]},{"cell_type":"code","execution_count":58,"metadata":{"executionInfo":{"elapsed":466,"status":"ok","timestamp":1686378513800,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"TuGw5kznuV9k"},"outputs":[],"source":["class Encoder(tf.keras.layers.Layer):\n","  def __init__(self, embedder, num_layers, d_model, num_heads,\n","               dff, vocab_size, dropout_rate=0.1):\n","    super().__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","\n","    self.embedding = embedder#tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n","    # self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model)\n","\n","    self.enc_layers = [\n","        EncoderLayer(d_model=d_model,\n","                     num_heads=num_heads,\n","                     dff=dff,\n","                     dropout_rate=dropout_rate)\n","        for _ in range(num_layers)]\n","    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","\n","  def call(self, x):\n","    # `x` is token-IDs shape: (batch, seq_len)\n","    x = self.embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n","\n","    # Add dropout.\n","    x = self.dropout(x)\n","\n","    for i in range(self.num_layers):\n","      x = self.enc_layers[i](x)\n","\n","    return x  # Shape `(batch_size, seq_len, d_model)`."]},{"cell_type":"code","execution_count":59,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1686378514610,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"ig1-NZazuV9m"},"outputs":[],"source":["class DecoderLayer(tf.keras.layers.Layer):\n","  def __init__(self,\n","               *,\n","               d_model,\n","               num_heads,\n","               dff,\n","               dropout_rate=0.1):\n","    super(DecoderLayer, self).__init__()\n","\n","    self.causal_self_attention = CausalSelfAttention(\n","        num_heads=num_heads,\n","        key_dim=d_model,\n","        dropout=dropout_rate)\n","\n","    self.cross_attention = CrossAttention(\n","        num_heads=num_heads,\n","        key_dim=d_model,\n","        dropout=dropout_rate)\n","\n","    self.ffn = FeedForward(d_model, dff)\n","\n","  def call(self, x, context):\n","    x = self.causal_self_attention(x=x)\n","    x = self.cross_attention(x=x, context=context)\n","\n","    # Cache the last attention scores for plotting later\n","    self.last_attn_scores = self.cross_attention.last_attn_scores\n","\n","    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n","    return x"]},{"cell_type":"code","execution_count":60,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1686378516104,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"biW3fEcNuV9o"},"outputs":[],"source":["class Decoder(tf.keras.layers.Layer):\n","  def __init__(self, embedder, num_layers, d_model, num_heads, dff, vocab_size,\n","               dropout_rate=0.1):\n","    super(Decoder, self).__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","\n","    self.pos_embedding = PositionalEmbedding(embedder, vocab_size=vocab_size, d_model=d_model)\n","\n","    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","    self.dec_layers = [\n","        DecoderLayer(d_model=d_model, num_heads=num_heads,\n","                     dff=dff, dropout_rate=dropout_rate)\n","        for _ in range(num_layers)]\n","\n","    self.last_attn_scores = None\n","\n","  def call(self, x, context):\n","    # `x` is token-IDs shape (batch, target_seq_len)\n","    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n","\n","    x = self.dropout(x)\n","\n","    for i in range(self.num_layers):\n","      x  = self.dec_layers[i](x, context)\n","\n","    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n","\n","    # The shape of x is (batch_size, target_seq_len, d_model).\n","    return x"]},{"cell_type":"code","execution_count":61,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1686378518009,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"neyeKofGuV9p"},"outputs":[],"source":["class Transformer(tf.keras.Model):\n","  def __init__(self, *, num_layers, d_model, num_heads, dff,\n","               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n","    super().__init__()\n","    self.embedder = tf.keras.layers.Embedding(input_vocab_size, d_model, mask_zero=True)\n","    self.encoder = Encoder(self.embedder,num_layers=num_layers, d_model=d_model,\n","                           num_heads=num_heads, dff=dff,\n","                           vocab_size=input_vocab_size,\n","                           dropout_rate=dropout_rate)\n","\n","    self.decoder = Decoder(self.embedder,num_layers=num_layers, d_model=d_model,\n","                           num_heads=num_heads, dff=dff,\n","                           vocab_size=target_vocab_size,\n","                           dropout_rate=dropout_rate)\n","\n","    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","\n","  def call(self, inputs):\n","    # To use a Keras model with `.fit` you must pass all your inputs in the\n","    # first argument.\n","    context, x  = inputs\n","\n","    context = self.encoder(context)  # (batch_size, context_len, d_model)\n","\n","    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n","\n","    # Final linear layer output.\n","    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n","\n","    try:\n","      # Drop the keras mask, so it doesn't scale the losses/metrics.\n","      # b/250038731\n","      del logits._keras_mask\n","    except AttributeError:\n","      pass\n","\n","    # Return the final output and the attention weights.\n","    return logits"]},{"cell_type":"code","execution_count":62,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1686378519786,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"TchyLG6CuV9q"},"outputs":[],"source":["# hyper-parameters of the Model\n","\n","num_layers = 4\n","d_model = 160\n","dff = 512\n","num_heads = 8\n","dropout_rate = 0.2"]},{"cell_type":"code","execution_count":63,"metadata":{"executionInfo":{"elapsed":3289,"status":"ok","timestamp":1686378524599,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"B4kcULMtuV9r"},"outputs":[],"source":["transformer = Transformer(\n","    num_layers=num_layers,\n","    d_model=d_model,\n","    num_heads=num_heads,\n","    dff=dff,\n","    input_vocab_size=10_000,\n","    target_vocab_size=10_000,\n","    dropout_rate=dropout_rate)"]},{"cell_type":"code","execution_count":64,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1686378524600,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"g895ub36uV9t"},"outputs":[],"source":["# CustomSchedule allows to have a learning which is higher in the first part of the training and then decreases\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super().__init__()\n","\n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","    self.warmup_steps = warmup_steps\n","\n","  def __call__(self, step):\n","    step = tf.cast(step, dtype=tf.float32)\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps ** -1.5)\n","\n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"]},{"cell_type":"code","execution_count":65,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1686378524600,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"_dOUW2zXuV9v"},"outputs":[],"source":["learning_rate = CustomSchedule(d_model)\n","\n","# using Adam as optimizer with the learning rate schedule\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n","                                     epsilon=1e-9)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DjhZe9ZyQbCM"},"source":["## Custom Loss Function\n","\n","The aim of this custom loss is to create a mask which gives more importance to the first words in the sentence.\n","\n","The key idea is that if the transformer learns well how to generate the first few words, then it will perform better having the first part of the string correctly generated.\n","\n","The workflow for the custom loss is the following:\n","*   a constant value is given, in this case K_VALUE=0.97\n","*   the mask is created as a boolean vector given by label != 0 (ignoring padding)\n","*  the sparse categorical crossentropy is computed between the ground truth and the predicted value\n","*  then the boolean mask is multiplied by a tensor which contains value like K_VALUE**(i)  for i in 1...max_sequence_len, so there is an higher value in the first element and smaller value as we move further in the tensor\n","*  the mask is computed by multiplying the original boolean mask with the tensor created at the previous step (to ignore padding)\n","* the loss is computed by multipling the loss computed by the sparse categorical crossentropy with the mask\n","\n","This function can be customized by changing the K_VALUE and the exponent of the tensor.\n","\n","Another idea (tested with little worse results) is to create a custom shifting loss function, which starts giving more weights to the first words and then shifts the focus to the other parts of the sequence as learning phase goes on. In order to obtain such a results, I used a callbacks which changes the focus of the loss function based on the epoch number."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oXu-SCA7hpr8"},"source":["# Accuracy Metrics\n","The accuracy is taken from the tensorflow tutorial and comptues the accuracy between the ground truth and the predicted label by ignoring the padding, to have a more reliable value"]},{"cell_type":"code","execution_count":66,"metadata":{"executionInfo":{"elapsed":433,"status":"ok","timestamp":1686378535987,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"y4t93vd1uV9w"},"outputs":[],"source":["K_VALUE = 0.97\n","\n","def custom_masked_loss(label, pred):\n","    mask = label != 0\n","    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","        from_logits=True, reduction='none')\n","    loss = loss_object(label, pred)\n","\n","    a = tf.cast(tf.range(1,max_sequence_len+1),tf.float32)\n","    constant_val = tf.constant(K_VALUE)\n","    final_array = tf.pow(constant_val,a)\n","\n","    mask = tf.cast(mask, dtype=loss.dtype)\n","    mask*=final_array\n","\n","    loss *= mask\n","\n","    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n","    return loss\n","\n","\n","def masked_accuracy(label, pred): \n","    pred = tf.argmax(pred, axis=2)\n","    label = tf.cast(label, pred.dtype)\n","    match = label == pred\n","\n","    mask = label != 0\n","\n","    match = match & mask\n","\n","    match = tf.cast(match, dtype=tf.float32)\n","    mask = tf.cast(mask, dtype=tf.float32)\n","    return tf.reduce_sum(match)/tf.reduce_sum(mask)"]},{"cell_type":"code","execution_count":67,"metadata":{"executionInfo":{"elapsed":448,"status":"ok","timestamp":1686378538055,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"5l8NDFi5uV9x"},"outputs":[],"source":["# compiling the model using the custom loss function, the optimizer defined above and the masked accuracy metric\n","transformer.compile(\n","    loss=custom_masked_loss,\n","    optimizer=optimizer,\n","    metrics=[masked_accuracy])"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11754480,"status":"ok","timestamp":1686390299557,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"BLL4no5mGLgv","outputId":"675464d2-b367-4a37-9e0a-b6f304886f24"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","565/565 [==============================] - 344s 525ms/step - loss: 7.2669 - masked_accuracy: 0.1674 - val_loss: 5.3164 - val_masked_accuracy: 0.3095\n","Epoch 2/100\n","565/565 [==============================] - 281s 497ms/step - loss: 4.1337 - masked_accuracy: 0.4065 - val_loss: 2.8858 - val_masked_accuracy: 0.5434\n","Epoch 3/100\n","565/565 [==============================] - 280s 496ms/step - loss: 2.4715 - masked_accuracy: 0.5749 - val_loss: 1.7634 - val_masked_accuracy: 0.6574\n","Epoch 4/100\n","565/565 [==============================] - 270s 477ms/step - loss: 1.6395 - masked_accuracy: 0.6637 - val_loss: 1.2048 - val_masked_accuracy: 0.7297\n","Epoch 5/100\n","565/565 [==============================] - 270s 478ms/step - loss: 1.2937 - masked_accuracy: 0.7044 - val_loss: 1.0325 - val_masked_accuracy: 0.7525\n","Epoch 6/100\n","565/565 [==============================] - 269s 477ms/step - loss: 1.1332 - masked_accuracy: 0.7269 - val_loss: 0.9188 - val_masked_accuracy: 0.7723\n","Epoch 7/100\n","565/565 [==============================] - 279s 494ms/step - loss: 1.0332 - masked_accuracy: 0.7430 - val_loss: 0.8511 - val_masked_accuracy: 0.7826\n","Epoch 8/100\n","565/565 [==============================] - 270s 478ms/step - loss: 0.9516 - masked_accuracy: 0.7568 - val_loss: 0.7941 - val_masked_accuracy: 0.7951\n","Epoch 9/100\n","565/565 [==============================] - 279s 494ms/step - loss: 0.8656 - masked_accuracy: 0.7728 - val_loss: 0.7519 - val_masked_accuracy: 0.7992\n","Epoch 10/100\n","565/565 [==============================] - 284s 502ms/step - loss: 0.8015 - masked_accuracy: 0.7845 - val_loss: 0.7172 - val_masked_accuracy: 0.8079\n","Epoch 11/100\n","565/565 [==============================] - 282s 499ms/step - loss: 0.7520 - masked_accuracy: 0.7942 - val_loss: 0.6736 - val_masked_accuracy: 0.8172\n","Epoch 12/100\n","565/565 [==============================] - 271s 480ms/step - loss: 0.7104 - masked_accuracy: 0.8026 - val_loss: 0.6485 - val_masked_accuracy: 0.8217\n","Epoch 13/100\n","565/565 [==============================] - 282s 499ms/step - loss: 0.6778 - masked_accuracy: 0.8093 - val_loss: 0.6243 - val_masked_accuracy: 0.8269\n","Epoch 14/100\n","565/565 [==============================] - 282s 499ms/step - loss: 0.6481 - masked_accuracy: 0.8156 - val_loss: 0.6275 - val_masked_accuracy: 0.8264\n","Epoch 15/100\n","565/565 [==============================] - 280s 496ms/step - loss: 0.6239 - masked_accuracy: 0.8206 - val_loss: 0.5956 - val_masked_accuracy: 0.8343\n","Epoch 16/100\n","565/565 [==============================] - 283s 501ms/step - loss: 0.6021 - masked_accuracy: 0.8256 - val_loss: 0.5840 - val_masked_accuracy: 0.8382\n","Epoch 17/100\n","565/565 [==============================] - 279s 493ms/step - loss: 0.5826 - masked_accuracy: 0.8299 - val_loss: 0.5673 - val_masked_accuracy: 0.8414\n","Epoch 18/100\n","565/565 [==============================] - 279s 494ms/step - loss: 0.5659 - masked_accuracy: 0.8338 - val_loss: 0.5445 - val_masked_accuracy: 0.8471\n","Epoch 19/100\n","565/565 [==============================] - 279s 493ms/step - loss: 0.5505 - masked_accuracy: 0.8372 - val_loss: 0.5429 - val_masked_accuracy: 0.8474\n","Epoch 20/100\n","565/565 [==============================] - 278s 493ms/step - loss: 0.5361 - masked_accuracy: 0.8404 - val_loss: 0.5409 - val_masked_accuracy: 0.8478\n","Epoch 21/100\n","565/565 [==============================] - 271s 480ms/step - loss: 0.5236 - masked_accuracy: 0.8435 - val_loss: 0.5381 - val_masked_accuracy: 0.8493\n","Epoch 22/100\n","565/565 [==============================] - 273s 483ms/step - loss: 0.5114 - masked_accuracy: 0.8463 - val_loss: 0.5262 - val_masked_accuracy: 0.8523\n","Epoch 23/100\n","565/565 [==============================] - 280s 495ms/step - loss: 0.4995 - masked_accuracy: 0.8494 - val_loss: 0.5224 - val_masked_accuracy: 0.8529\n","Epoch 24/100\n","565/565 [==============================] - 270s 478ms/step - loss: 0.4893 - masked_accuracy: 0.8520 - val_loss: 0.5145 - val_masked_accuracy: 0.8546\n","Epoch 25/100\n","565/565 [==============================] - 280s 496ms/step - loss: 0.4795 - masked_accuracy: 0.8543 - val_loss: 0.5102 - val_masked_accuracy: 0.8558\n","Epoch 26/100\n","565/565 [==============================] - 280s 496ms/step - loss: 0.4700 - masked_accuracy: 0.8567 - val_loss: 0.5050 - val_masked_accuracy: 0.8576\n","Epoch 27/100\n","565/565 [==============================] - 280s 495ms/step - loss: 0.4610 - masked_accuracy: 0.8588 - val_loss: 0.4877 - val_masked_accuracy: 0.8619\n","Epoch 28/100\n","565/565 [==============================] - 280s 495ms/step - loss: 0.4533 - masked_accuracy: 0.8609 - val_loss: 0.4922 - val_masked_accuracy: 0.8611\n","Epoch 29/100\n","565/565 [==============================] - 280s 495ms/step - loss: 0.4463 - masked_accuracy: 0.8628 - val_loss: 0.4926 - val_masked_accuracy: 0.8622\n","Epoch 30/100\n","565/565 [==============================] - 272s 482ms/step - loss: 0.4390 - masked_accuracy: 0.8646 - val_loss: 0.4934 - val_masked_accuracy: 0.8617\n","Epoch 31/100\n","565/565 [==============================] - 277s 491ms/step - loss: 0.4318 - masked_accuracy: 0.8663 - val_loss: 0.4881 - val_masked_accuracy: 0.8630\n","Epoch 32/100\n","565/565 [==============================] - 281s 498ms/step - loss: 0.4256 - masked_accuracy: 0.8680 - val_loss: 0.4814 - val_masked_accuracy: 0.8642\n","Epoch 33/100\n","565/565 [==============================] - 283s 501ms/step - loss: 0.4194 - masked_accuracy: 0.8696 - val_loss: 0.4773 - val_masked_accuracy: 0.8659\n","Epoch 34/100\n","565/565 [==============================] - 274s 485ms/step - loss: 0.4130 - masked_accuracy: 0.8711 - val_loss: 0.4803 - val_masked_accuracy: 0.8654\n","Epoch 35/100\n","565/565 [==============================] - 286s 506ms/step - loss: 0.4071 - masked_accuracy: 0.8726 - val_loss: 0.4727 - val_masked_accuracy: 0.8677\n","Epoch 36/100\n","565/565 [==============================] - 284s 502ms/step - loss: 0.4020 - masked_accuracy: 0.8741 - val_loss: 0.4678 - val_masked_accuracy: 0.8690\n","Epoch 37/100\n","565/565 [==============================] - 282s 499ms/step - loss: 0.3970 - masked_accuracy: 0.8756 - val_loss: 0.4677 - val_masked_accuracy: 0.8681\n","Epoch 38/100\n","565/565 [==============================] - 281s 497ms/step - loss: 0.3919 - masked_accuracy: 0.8769 - val_loss: 0.4645 - val_masked_accuracy: 0.8693\n","Epoch 39/100\n","565/565 [==============================] - 280s 495ms/step - loss: 0.3870 - masked_accuracy: 0.8783 - val_loss: 0.4604 - val_masked_accuracy: 0.8712\n","Epoch 40/100\n","565/565 [==============================] - 281s 497ms/step - loss: 0.3822 - masked_accuracy: 0.8795 - val_loss: 0.4556 - val_masked_accuracy: 0.8723\n","Epoch 41/100\n","565/565 [==============================] - 279s 493ms/step - loss: 0.3776 - masked_accuracy: 0.8808 - val_loss: 0.4561 - val_masked_accuracy: 0.8718\n","Epoch 42/100\n","565/565 [==============================] - 279s 494ms/step - loss: 0.3731 - masked_accuracy: 0.8819 - val_loss: 0.4606 - val_masked_accuracy: 0.8715\n","Epoch 42: early stopping\n"]}],"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","# Callbacks\n","es = EarlyStopping(monitor='val_masked_accuracy', mode='max', verbose=1, patience=2)\n","\n","epochs = 100\n","batch_size=1024\n","\n","history = transformer.fit(\n","    (c_train, x_train),\n","    y_train,\n","    epochs=epochs,\n","    batch_size=batch_size,\n","    callbacks = [es],\n","    validation_split = 0.1\n",")"]},{"cell_type":"code","execution_count":69,"metadata":{"executionInfo":{"elapsed":3152,"status":"ok","timestamp":1686390354311,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"ap8z8rkYhlIW"},"outputs":[],"source":["# saving weights to save computation and just test\n","# transformer.save_weights(\"transformer_data_augmented/transformer\")"]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17745,"status":"ok","timestamp":1686390378876,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"tStocUZev5V1","outputId":"07c719ed-5fe2-4040-8f7f-69b1b515ac55"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# from google.colab import drive\n","# drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":71,"metadata":{"executionInfo":{"elapsed":1772,"status":"ok","timestamp":1686390382996,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"vawkrXYaaTil"},"outputs":[],"source":["# !cp -rf transformer_data_augmented /content/drive/MyDrive/Università/DL/Project/DataAugmentedVersion"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":346,"status":"ok","timestamp":1686390409214,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"xCKGtzIpnzdC","outputId":"b78a1a8b-2f03-4954-ef6d-5def1dcb6cfe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"transformer\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       multiple                  1600000   \n","                                                                 \n"," encoder (Encoder)           multiple                  5553408   \n","                                                                 \n"," decoder (Decoder)           multiple                  8847488   \n","                                                                 \n"," dense_16 (Dense)            multiple                  1610000   \n","                                                                 \n","=================================================================\n","Total params: 14,410,896\n","Trainable params: 14,410,896\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# summary of the model\n","transformer.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xr0YUF8cEbEi"},"outputs":[],"source":["# transformer.load_weights(\"transformer_data_augmented/transformer\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"S6Wf_R4DiZtf"},"source":["# Translator\n","The aim of this class is to define an object which, when called, takes in input a batch of shuffled sentences and gives as results the output of the transformer.\n","\n"]},{"cell_type":"code","execution_count":73,"metadata":{"executionInfo":{"elapsed":312,"status":"ok","timestamp":1686390414611,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"B7_pDZgRY4Cb"},"outputs":[],"source":["import keras.backend as K\n","\n","class Translator(tf.Module):\n","    def __init__(self, transformer, tokenizer):\n","        self.transformer = transformer\n","        self.tokenizer = tokenizer\n","              \n","    def __call__(self, input_sentences, max_length=max_sequence_len):\n","        # batch size is the number of sentences passed in input\n","        batch_size = K.int_shape(input_sentences)[0]\n","        encoder_input = input_sentences\n","        # all the decoded sentences will start with the index of the token <start>\n","        decoded_indexes = [[self.tokenizer.word_index['<start>']] for _ in range(batch_size)]\n","\n","        # allowed words allows to filter the predictions of the model, restricting the choose of the predictions to the only word that were in the original shuffled sentences\n","        allowed_words = [ [word for word in sentence if word not in [sos, eos, 0]] for sentence in encoder_input]\n","\n","        for i in range(1, max_length):\n","            # preparing the input of the transformer\n","            decoder_input = tf.convert_to_tensor(decoded_indexes)\n","            # running the transformer on the partially decoded sentences\n","            predictions = np.array(self.transformer((np.array(encoder_input), np.array(decoder_input))))\n","            # slicing the prediction on the last tokens which are the ones we are interested in \n","            predictions = predictions[:, -1, :]\n","\n","            for j in range(batch_size):\n","                # if there are no more allowed words for a specific sentence, concatenate the eos token\n","                if len(allowed_words[j]) == 0:\n","                    best_token = eos\n","                # otherwise, filter the predicions on just the tokens remaining in the array allowed_words and keeps the best prediction for those as new token to be added to the sentence\n","                else:\n","                    filtered_predictions = predictions[j, np.array(allowed_words[j])]\n","                    best_index = np.argmax(filtered_predictions)\n","                    best_token = allowed_words[j][best_index]\n","\n","                    # removing the tokens sampled from the allowed_words\n","                    del allowed_words[j][best_index]\n","                # appending the best token to the decoded sentence\n","                decoded_indexes[j].append(best_token)\n","        return decoded_indexes"]},{"cell_type":"code","execution_count":74,"metadata":{"executionInfo":{"elapsed":304,"status":"ok","timestamp":1686390418777,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"oaK3OKwOBLjY"},"outputs":[],"source":["# helper function to remove useless tokens and additional spaces from a string\n","def process(sentence):\n","    return sentence.replace('<start>', '').replace('<pad>', '').replace('<end>', '').strip()"]},{"cell_type":"code","execution_count":75,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1686390420038,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"HOy4pM1-1thk"},"outputs":[],"source":["# defining the translator\n","translator = Translator(transformer, tokenizer)"]},{"cell_type":"code","execution_count":76,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":116028,"status":"ok","timestamp":1686390537901,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"38txoEmH15sT","outputId":"b8283e4f-29a3-47c8-ce70-bde2d67c410c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Computed: 1; Score: 0.5875923621772859\n","Computed: 2; Score: 0.605948240158856\n","Computed: 3; Score: 0.598907024723789\n","Computed: 4; Score: 0.592806493301154\n","Computed: 5; Score: 0.5872395224311262\n","Computed: 6; Score: 0.5923474967205714\n","Total score: 0.5923474967205714\n"]}],"source":["# testing the transformer with the translator object on 3k samples\n","# using batches of 500 samples allows the visualization of intermediate results and partial score as testing proceeds\n","\n","batch_size = 500\n","total = 3000\n","\n","sc = 0\n","for i in range(total//batch_size):\n","    # taking the corresponding batch from the shuffled and target sentences\n","    shuffled_sentences = c_test[i*batch_size :(i+1)*batch_size]\n","    original_sentences = y_test[i*batch_size :(i+1)*batch_size]\n","    # obtaining the results of the translator \n","    translated = translator(shuffled_sentences)\n","    for j in range(batch_size):\n","        # processing the several sentences\n","        single_shuffled = process(tokenizer.sequences_to_texts([shuffled_sentences[j]])[0])\n","\n","        single_translated = tokenizer.sequences_to_texts([translated[j]])[0]\n","        single_translated = single_translated.split(\"<end>\")[0]\n","        single_translated = process(single_translated)\n","        \n","        single_original = process(tokenizer.sequences_to_texts([original_sentences[j]])[0])\n","        \n","        # updating the score\n","        sc = sc + score(single_original, single_translated)\n","    print(f\"Computed: {i+1}; Score: {sc/((i+1)*batch_size)}\")\n","    \n","# final score\n","sc = sc/total\n","print(\"Total score:\", sc)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Beam Search Algorithm\n","Another useful optimization consist in using the Beam Search algorithm to generate the output sentence.\n","\n","The following code is an implementation of the Beam Search for decoding sentences. The idea is to keep track of the best K candidates for each sentence, where K is the beam size. At each step, the best K candidates are selected and the next word is predicted for each of them. Then, the K best candidates are selected and the process is repeated until the end of the sentence is reached."]},{"cell_type":"code","execution_count":77,"metadata":{"executionInfo":{"elapsed":537,"status":"ok","timestamp":1686390549172,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"hPGXNxjzxAIH"},"outputs":[],"source":["# inputs:\n","# - originals: list of original sentences\n","# - model: the trained model\n","# - tokenizer: the tokenizer used to encode the sentences\n","# - max_length: the maximum length of the sentences\n","# - beam_width: the number of candidates to keep at each step of the beam search\n","def beam_search_decode_sentences(originals, model, tokenizer, max_length=32, beam_width=3):\n","    # Initialize the decoder inputs with a start token\n","    batch_size = len(originals)\n","    decoder_inputs = np.zeros((batch_size, max_length))\n","    decoder_inputs[:, 0] = sos\n","\n","    # Initialize the beam search candidates\n","    candidate_lists = [[{'sequence': decoder_input, 'score': 1.0}] for decoder_input in decoder_inputs]\n","\n","    # Perform beam search decoding\n","    # At each step, the beam search algorithm finds the best candidates\n","    for i in range(1, max_length):\n","\n","        # Packing the inputs for the decoder\n","        packed_candidates = []\n","        packed_originals = []\n","        # the packing_indices are used to keep track of which candidate belongs to which original sentence\n","        packing_indices = []\n","        \n","        for sentence_index, (original, candidate_list) in enumerate(zip(originals, candidate_lists)):\n","            for candidate_index, candidate in enumerate(candidate_list):\n","                packed_candidates.append(candidate['sequence'])\n","                packed_originals.append(original)\n","                packing_indices.append((sentence_index, candidate_index))\n","            \n","        packed_candidates = np.array(packed_candidates)\n","        packed_originals = np.array(packed_originals)\n","\n","        # Get the predictions for this set of inputs\n","        predictions = model.predict((packed_originals, packed_candidates), verbose=False)\n","\n","        # Get the top predictions for each candidate\n","        predicted_indices = np.argsort(predictions[:, i-1, :], axis=-1)#[:, -beam_width:]\n","\n","        new_candidate_lists = [list() for _ in range(len(candidate_lists))]\n","\n","        # For each candidate, add the top predictions to the list of candidates\n","        # by filtering out the ones that are not allowed (same reasoning as in the translator)\n","        for packed_index, (sentence_index, candidate_index) in enumerate(packing_indices):\n","            candidate = candidate_lists[sentence_index][candidate_index]\n","\n","            allowed = list([x for x in originals[sentence_index] if x not in [0, sos, eos]])\n","            for word in candidate['sequence']:\n","                try:\n","                    allowed.remove(word)\n","                except:\n","                    pass\n","            allowed = np.unique(np.array(allowed))\n","            relevant_indices = predicted_indices[packed_index]\n","            relevant_indices = relevant_indices[np.isin(relevant_indices, allowed)]\n","            relevant_indices = relevant_indices[-beam_width:]\n","\n","            # If there are no more allowed words, add an eos\n","            if len(relevant_indices) == 0:\n","                new_sequence = np.copy(candidate['sequence'])\n","                new_sequence[i] = eos\n","                new_score = candidate['score']\n","                new_candidate_lists[sentence_index].append({'sequence': new_sequence, 'score': new_score})\n","            else:\n","                # Add the top predictions to the list of candidates\n","                for m in range(min(len(relevant_indices), beam_width)):\n","                    new_sequence = np.copy(candidate['sequence'])\n","                    chosen_word = relevant_indices[m]\n","                    new_sequence[i] = chosen_word\n","                    new_score = candidate['score'] * predictions[packed_index, i-1, chosen_word]\n","\n","                    new_candidate_lists[sentence_index].append({'sequence': new_sequence, 'score': new_score})\n","\n","        # Sort the candidates by score\n","        sorted_new_candidate_lists = [sorted(new_candidate_list, key=lambda x: x['score'], reverse=True) for new_candidate_list in new_candidate_lists]\n","        \n","        # Keep only the top candidates\n","        candidate_lists = [candidate_list[:beam_width] for candidate_list in sorted_new_candidate_lists]\n","\n","    # Select the best candidate as the output sequence\n","    best_candidates = [candidate_list[0]['sequence'] for candidate_list in candidate_lists]\n","    output_sentences = [''] * batch_size\n","    for j in range(batch_size):\n","        for i in range(1, max_length):\n","            predicted_index = int(best_candidates[j][i])\n","            predicted_word = tokenizer.index_word[predicted_index]\n","\n","            if predicted_word == '<end>':\n","                break\n","\n","            output_sentences[j] += predicted_word + ' '\n","    # Return the output sentences \n","    return [output_sentence.strip() for output_sentence in output_sentences]"]},{"cell_type":"code","execution_count":78,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1330326,"status":"ok","timestamp":1686391935937,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"mf4Ff_CHIau0","outputId":"df4eee39-b6fc-4a4a-e3fb-e548ab04f11a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Computed: 250; Score: 0.5969412690813549\n","Computed: 500; Score: 0.6021966634283522\n","Computed: 750; Score: 0.6164446986404143\n","Computed: 1000; Score: 0.622399580095514\n","Computed: 1250; Score: 0.6184924543419494\n","Computed: 1500; Score: 0.6146871525629856\n","Computed: 1750; Score: 0.6067906248124834\n","Computed: 2000; Score: 0.6074176653296844\n","Computed: 2250; Score: 0.6048158154171558\n","Computed: 2500; Score: 0.602389833481145\n","Computed: 2750; Score: 0.602505215443995\n","Computed: 3000; Score: 0.6053393596679355\n"]}],"source":["# testint the beam search on 3k samples with a beam width of 4\n","# using batches of 250 samples allows the visualization of intermediate results and partial score as testing proceeds\n","\n","batch_size = 250\n","total = 3000\n","\n","all_scores = []\n","for i in range(total//batch_size):\n","    shuffled_sentences = c_test[i*batch_size:(i+1)*batch_size]\n","    original_sentences = y_test[i*batch_size:(i+1)*batch_size]\n","    translated_sentences = beam_search_decode_sentences(np.array(shuffled_sentences), transformer, tokenizer, beam_width=4)\n","\n","\n","    processed_shuffled = [process(tokenizer.sequences_to_texts([shuffled_sentence])[0]) for shuffled_sentence in shuffled_sentences]\n","\n","    translated_sentences = [translated_sentence.split(\"<end>\")[0] for translated_sentence in translated_sentences]\n","    translated_sentences = [process(translated_sentence) for translated_sentence in translated_sentences]\n","    \n","    processed_originals = [process(tokenizer.sequences_to_texts([original_sentence])[0]) for original_sentence in original_sentences]\n","    \n","    all_scores += [score(single_original, single_translated) for single_original, single_translated in zip(processed_originals, translated_sentences)]\n","    print(f\"Computed: {len(all_scores)}; Score: {np.mean(all_scores)}\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["As can be seen from the results, there are slightly better results using the Beam Search algorithm, but the difference is not so big."]},{"cell_type":"code","execution_count":79,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"executionInfo":{"elapsed":413,"status":"ok","timestamp":1686391952963,"user":{"displayName":"Andrea Zecca","userId":"08710816336383652707"},"user_tz":-120},"id":"BLWiLxDnfmkW","outputId":"bae982c7-daf0-4415-e82f-435ea4eca829"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhIklEQVR4nO3dfXBU5d2H8W9eyCZiNuGl2c3WAJFaIYqiROMCapUMUZCWkVYZUxotJS0mVgiKSZGggARTixQaSaFqmBGLtSNWAaNpEKgSAwbSUt7UAgKlm+hgsoAlr+f5ow9bV1EJ3c3mDtdnZmeac+6z+1tPMZcnm0OYZVmWAAAADBIe6gEAAAA6ioABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYJzIUA8QLO3t7Tp69KhiY2MVFhYW6nEAAMBZsCxLx48fl8vlUnj4l19n6bYBc/ToUSUlJYV6DAAAcA4OHz6siy666Ev3d9uAiY2NlfSffwB2uz3E0wAAgLPh9XqVlJTk+z7+ZbptwJz+sZHdbidgAAAwzNd9/IMP8QIAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDiRoR4AAIDz3YD8daEeocMOLhwb0tfnCgwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIzT4YDZvHmzxo0bJ5fLpbCwML388st++y3LUmFhoRITExUTE6P09HS9//77fmuOHTumzMxM2e12xcfHa/LkyTpx4oTfmr/97W+6/vrrFR0draSkJBUXF3f83QEAgG6pwwFz8uRJXXnllSopKTnj/uLiYi1ZskSlpaWqrq5Wz549lZGRoVOnTvnWZGZmateuXaqoqNDatWu1efNmZWdn+/Z7vV6NHj1a/fv3V01NjX75y1/qkUce0fLly8/hLQIAgO4mzLIs65wPDgvTmjVrNH78eEn/ufricrk0Y8YMPfDAA5KkxsZGORwOlZWVaeLEidqzZ49SUlK0bds2paamSpLKy8s1ZswYHTlyRC6XS8uWLdOsWbPk8XgUFRUlScrPz9fLL7+svXv3ntVsXq9XcXFxamxslN1uP9e3CABA0A3IXxfqETrs4MKxQXnes/3+HdDPwBw4cEAej0fp6em+bXFxcUpLS1NVVZUkqaqqSvHx8b54kaT09HSFh4erurrat+aGG27wxYskZWRkaN++ffrkk0/O+NpNTU3yer1+DwAA0D0FNGA8Ho8kyeFw+G13OBy+fR6PRwkJCX77IyMj1bt3b781Z3qOz77G5xUVFSkuLs73SEpK+t/fEAAA6JK6zW8hFRQUqLGx0fc4fPhwqEcCAABBEtCAcTqdkqS6ujq/7XV1db59TqdT9fX1fvtbW1t17NgxvzVneo7Pvsbn2Ww22e12vwcAAOieAhowycnJcjqdqqys9G3zer2qrq6W2+2WJLndbjU0NKimpsa3ZsOGDWpvb1daWppvzebNm9XS0uJbU1FRoUsvvVS9evUK5MgAAMBAHQ6YEydOqLa2VrW1tZL+88Hd2tpaHTp0SGFhYZo2bZrmz5+vV155RTt37tSPfvQjuVwu328qDR48WLfccoumTJmirVu36u2331Zubq4mTpwol8slSbrrrrsUFRWlyZMna9euXXrhhRf061//Wnl5eQF74wAAwFyRHT3g3Xff1U033eT7+nRUZGVlqaysTDNnztTJkyeVnZ2thoYGjRw5UuXl5YqOjvYds2rVKuXm5mrUqFEKDw/XhAkTtGTJEt/+uLg4vfHGG8rJydGwYcPUt29fFRYW+t0rBgAAnL/+p/vAdGXcBwYAYAruA/NfIbkPDAAAQGcgYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYJ+AB09bWptmzZys5OVkxMTEaOHCg5s2bJ8uyfGssy1JhYaESExMVExOj9PR0vf/++37Pc+zYMWVmZsputys+Pl6TJ0/WiRMnAj0uAAAwUMAD5vHHH9eyZcv0m9/8Rnv27NHjjz+u4uJiLV261LemuLhYS5YsUWlpqaqrq9WzZ09lZGTo1KlTvjWZmZnatWuXKioqtHbtWm3evFnZ2dmBHhcAABgozPrspZEAuO222+RwOPT000/7tk2YMEExMTF67rnnZFmWXC6XZsyYoQceeECS1NjYKIfDobKyMk2cOFF79uxRSkqKtm3bptTUVElSeXm5xowZoyNHjsjlcn3tHF6vV3FxcWpsbJTdbg/kWwQAIKAG5K8L9QgddnDh2KA879l+/w74FZjhw4ersrJS7733niTpr3/9q9566y3deuutkqQDBw7I4/EoPT3dd0xcXJzS0tJUVVUlSaqqqlJ8fLwvXiQpPT1d4eHhqq6uPuPrNjU1yev1+j0AAED3FBnoJ8zPz5fX69WgQYMUERGhtrY2PfbYY8rMzJQkeTweSZLD4fA7zuFw+PZ5PB4lJCT4DxoZqd69e/vWfF5RUZEeffTRQL8dAADQBQX8Cswf/vAHrVq1Ss8//7y2b9+ulStX6oknntDKlSsD/VJ+CgoK1NjY6HscPnw4qK8HAABCJ+BXYB588EHl5+dr4sSJkqQhQ4boww8/VFFRkbKysuR0OiVJdXV1SkxM9B1XV1enoUOHSpKcTqfq6+v9nre1tVXHjh3zHf95NptNNpst0G8HAAB0QQG/AvPpp58qPNz/aSMiItTe3i5JSk5OltPpVGVlpW+/1+tVdXW13G63JMntdquhoUE1NTW+NRs2bFB7e7vS0tICPTIAADBMwK/AjBs3To899pj69eunyy67TDt27NCiRYv04x//WJIUFhamadOmaf78+brkkkuUnJys2bNny+Vyafz48ZKkwYMH65ZbbtGUKVNUWlqqlpYW5ebmauLEiWf1G0gAAKB7C3jALF26VLNnz9a9996r+vp6uVwu/fSnP1VhYaFvzcyZM3Xy5EllZ2eroaFBI0eOVHl5uaKjo31rVq1apdzcXI0aNUrh4eGaMGGClixZEuhxAQCAgQJ+H5iugvvAAABMwX1g/itk94EBAAAINgIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYJSsD885//1A9/+EP16dNHMTExGjJkiN59913ffsuyVFhYqMTERMXExCg9PV3vv/++33McO3ZMmZmZstvtio+P1+TJk3XixIlgjAsAAAwT8ID55JNPNGLECPXo0UOvvfaadu/erV/96lfq1auXb01xcbGWLFmi0tJSVVdXq2fPnsrIyNCpU6d8azIzM7Vr1y5VVFRo7dq12rx5s7KzswM9LgAAMFCYZVlWIJ8wPz9fb7/9tv7yl7+ccb9lWXK5XJoxY4YeeOABSVJjY6McDofKyso0ceJE7dmzRykpKdq2bZtSU1MlSeXl5RozZoyOHDkil8v1tXN4vV7FxcWpsbFRdrs9cG8QAIAAG5C/LtQjdNjBhWOD8rxn+/074FdgXnnlFaWmpuoHP/iBEhISdNVVV2nFihW+/QcOHJDH41F6erpvW1xcnNLS0lRVVSVJqqqqUnx8vC9eJCk9PV3h4eGqrq4+4+s2NTXJ6/X6PQAAQPcU8IDZv3+/li1bpksuuUSvv/66pk6dqp///OdauXKlJMnj8UiSHA6H33EOh8O3z+PxKCEhwW9/ZGSkevfu7VvzeUVFRYqLi/M9kpKSAv3WAABAFxHwgGlvb9fVV1+tBQsW6KqrrlJ2dramTJmi0tLSQL+Un4KCAjU2Nvoehw8fDurrAQCA0Al4wCQmJiolJcVv2+DBg3Xo0CFJktPplCTV1dX5ramrq/Ptczqdqq+v99vf2tqqY8eO+dZ8ns1mk91u93sAAIDuKeABM2LECO3bt89v23vvvaf+/ftLkpKTk+V0OlVZWenb7/V6VV1dLbfbLUlyu91qaGhQTU2Nb82GDRvU3t6utLS0QI8MAAAMExnoJ5w+fbqGDx+uBQsW6I477tDWrVu1fPlyLV++XJIUFhamadOmaf78+brkkkuUnJys2bNny+Vyafz48ZL+c8Xmlltu8f3oqaWlRbm5uZo4ceJZ/QYSAADo3gIeMNdcc43WrFmjgoICzZ07V8nJyVq8eLEyMzN9a2bOnKmTJ08qOztbDQ0NGjlypMrLyxUdHe1bs2rVKuXm5mrUqFEKDw/XhAkTtGTJkkCPCwAADBTw+8B0FdwHBgBgCu4D818huw8MAABAsBEwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADBOZKgHQOcYkL8u1COck4MLx4Z6BABAFxT0gFm4cKEKCgp0//33a/HixZKkU6dOacaMGVq9erWampqUkZGhp556Sg6Hw3fcoUOHNHXqVL355pu68MILlZWVpaKiIkVG0lznExPDi+gCgOAL6o+Qtm3bpt/+9re64oor/LZPnz5dr776ql588UVt2rRJR48e1e233+7b39bWprFjx6q5uVlbtmzRypUrVVZWpsLCwmCOCwAADBG0gDlx4oQyMzO1YsUK9erVy7e9sbFRTz/9tBYtWqSbb75Zw4YN07PPPqstW7bonXfekSS98cYb2r17t5577jkNHTpUt956q+bNm6eSkhI1NzcHa2QAAGCIoAVMTk6Oxo4dq/T0dL/tNTU1amlp8ds+aNAg9evXT1VVVZKkqqoqDRkyxO9HShkZGfJ6vdq1a9cZX6+pqUler9fvAQAAuqegfKBk9erV2r59u7Zt2/aFfR6PR1FRUYqPj/fb7nA45PF4fGs+Gy+n95/edyZFRUV69NFHAzA9AADo6gJ+Bebw4cO6//77tWrVKkVHRwf66b9UQUGBGhsbfY/Dhw932msDAIDOFfCAqampUX19va6++mpFRkYqMjJSmzZt0pIlSxQZGSmHw6Hm5mY1NDT4HVdXVyen0ylJcjqdqqur+8L+0/vOxGazyW63+z0AAED3FPCAGTVqlHbu3Kna2lrfIzU1VZmZmb7/3aNHD1VWVvqO2bdvnw4dOiS32y1Jcrvd2rlzp+rr631rKioqZLfblZKSEuiRAQCAYQL+GZjY2Fhdfvnlftt69uypPn36+LZPnjxZeXl56t27t+x2u+677z653W5dd911kqTRo0crJSVFkyZNUnFxsTwejx5++GHl5OTIZrMFemQAAGCYkNwV7sknn1R4eLgmTJjgdyO70yIiIrR27VpNnTpVbrdbPXv2VFZWlubOnRuKcQEAQBfTKQGzceNGv6+jo6NVUlKikpKSLz2mf//+Wr9+fZAnAwAAJuIvcwQAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxokM9QBAdzMgf12oR+iwgwvHhnoEAOgQrsAAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIwTGeoBAITegPx1oR6hww4uHBvqEQCEEFdgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYJeMAUFRXpmmuuUWxsrBISEjR+/Hjt27fPb82pU6eUk5OjPn366MILL9SECRNUV1fnt+bQoUMaO3asLrjgAiUkJOjBBx9Ua2troMcFAAAGCnjAbNq0STk5OXrnnXdUUVGhlpYWjR49WidPnvStmT59ul599VW9+OKL2rRpk44eParbb7/dt7+trU1jx45Vc3OztmzZopUrV6qsrEyFhYWBHhcAABgozLIsK5gv8NFHHykhIUGbNm3SDTfcoMbGRn3jG9/Q888/r+9///uSpL1792rw4MGqqqrSddddp9dee0233Xabjh49KofDIUkqLS3VQw89pI8++khRUVFf+7per1dxcXFqbGyU3W4P5ls0woD8daEeAQiogwvHhnoEIGBM/Hd0sP4Mnu3376B/BqaxsVGS1Lt3b0lSTU2NWlpalJ6e7lszaNAg9evXT1VVVZKkqqoqDRkyxBcvkpSRkSGv16tdu3YFe2QAANDFRQbzydvb2zVt2jSNGDFCl19+uSTJ4/EoKipK8fHxfmsdDoc8Ho9vzWfj5fT+0/vOpKmpSU1NTb6vvV5voN4GAADoYoJ6BSYnJ0d///vftXr16mC+jKT/fHg4Li7O90hKSgr6awIAgNAI2hWY3NxcrV27Vps3b9ZFF13k2+50OtXc3KyGhga/qzB1dXVyOp2+NVu3bvV7vtO/pXR6zecVFBQoLy/P97XX6yVigG6MzwwA57eAX4GxLEu5ublas2aNNmzYoOTkZL/9w4YNU48ePVRZWenbtm/fPh06dEhut1uS5Ha7tXPnTtXX1/vWVFRUyG63KyUl5Yyva7PZZLfb/R4AAKB7CvgVmJycHD3//PP605/+pNjYWN9nVuLi4hQTE6O4uDhNnjxZeXl56t27t+x2u+677z653W5dd911kqTRo0crJSVFkyZNUnFxsTwejx5++GHl5OTIZrMFemQAAGCYgAfMsmXLJEnf+c53/LY/++yzuvvuuyVJTz75pMLDwzVhwgQ1NTUpIyNDTz31lG9tRESE1q5dq6lTp8rtdqtnz57KysrS3LlzAz0uAAAwUMAD5mxuKxMdHa2SkhKVlJR86Zr+/ftr/fr1gRwNAAB0E/xdSAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADBOZKgHAIDzxYD8daEeocMOLhwb6hGAM+IKDAAAMA4BAwAAjEPAAAAA4/AZmHNg4s+xAQDoTrgCAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjMPfRg0A+FID8teFeoQOO7hwbKhHQCfgCgwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAONzIDgDQrZh48z10HFdgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGCcLh0wJSUlGjBggKKjo5WWlqatW7eGeiQAANAFdNmAeeGFF5SXl6c5c+Zo+/btuvLKK5WRkaH6+vpQjwYAAEKsywbMokWLNGXKFN1zzz1KSUlRaWmpLrjgAj3zzDOhHg0AAIRYl7wTb3Nzs2pqalRQUODbFh4ervT0dFVVVZ3xmKamJjU1Nfm+bmxslCR5vd6Az9fe9GnAnxMAAJME4/vrZ5/XsqyvXNclA+bjjz9WW1ubHA6H33aHw6G9e/ee8ZiioiI9+uijX9ielJQUlBkBADifxS0O7vMfP35ccXFxX7q/SwbMuSgoKFBeXp7v6/b2dh07dkx9+vRRWFhYCCfrPrxer5KSknT48GHZ7fZQj3Ne4hyEHucg9DgHoRfMc2BZlo4fPy6Xy/WV67pkwPTt21cRERGqq6vz215XVyen03nGY2w2m2w2m9+2+Pj4YI14XrPb7fxLI8Q4B6HHOQg9zkHoBescfNWVl9O65Id4o6KiNGzYMFVWVvq2tbe3q7KyUm63O4STAQCArqBLXoGRpLy8PGVlZSk1NVXXXnutFi9erJMnT+qee+4J9WgAACDEumzA3Hnnnfroo49UWFgoj8ejoUOHqry8/Asf7EXnsdlsmjNnzhd+VIfOwzkIPc5B6HEOQq8rnIMw6+t+TwkAAKCL6ZKfgQEAAPgqBAwAADAOAQMAAIxDwAAAAOMQMPBTUlKiAQMGKDo6Wmlpadq6deuXrl2xYoWuv/569erVS7169VJ6evpXrsfZ6cg5+KzVq1crLCxM48ePD+6A54GOnoOGhgbl5OQoMTFRNptN3/72t7V+/fpOmrZ76ug5WLx4sS699FLFxMQoKSlJ06dP16lTpzpp2u5n8+bNGjdunFwul8LCwvTyyy9/7TEbN27U1VdfLZvNpm9961sqKysL7pAW8P9Wr15tRUVFWc8884y1a9cua8qUKVZ8fLxVV1d3xvV33XWXVVJSYu3YscPas2ePdffdd1txcXHWkSNHOnny7qOj5+C0AwcOWN/85jet66+/3vre977XOcN2Ux09B01NTVZqaqo1ZswY66233rIOHDhgbdy40aqtre3kybuPjp6DVatWWTabzVq1apV14MAB6/XXX7cSExOt6dOnd/Lk3cf69eutWbNmWS+99JIlyVqzZs1Xrt+/f791wQUXWHl5edbu3butpUuXWhEREVZ5eXnQZiRg4HPttddaOTk5vq/b2tosl8tlFRUVndXxra2tVmxsrLVy5cpgjdjtncs5aG1ttYYPH2797ne/s7KysgiY/1FHz8GyZcusiy++2Gpubu6sEbu9jp6DnJwc6+abb/bblpeXZ40YMSKoc54vziZgZs6caV122WV+2+68804rIyMjaHPxIyRIkpqbm1VTU6P09HTftvDwcKWnp6uqquqsnuPTTz9VS0uLevfuHawxu7VzPQdz585VQkKCJk+e3Bljdmvncg5eeeUVud1u5eTkyOFw6PLLL9eCBQvU1tbWWWN3K+dyDoYPH66amhrfj5n279+v9evXa8yYMZ0yM6Sqqiq/cyZJGRkZZ/3941x02TvxonN9/PHHamtr+8Kdjh0Oh/bu3XtWz/HQQw/J5XJ94f/EODvncg7eeustPf3006qtre2ECbu/czkH+/fv14YNG5SZman169frgw8+0L333quWlhbNmTOnM8buVs7lHNx11136+OOPNXLkSFmWpdbWVv3sZz/TL37xi84YGZI8Hs8Zz5nX69W///1vxcTEBPw1uQKDgFi4cKFWr16tNWvWKDo6OtTjnBeOHz+uSZMmacWKFerbt2+oxzlvtbe3KyEhQcuXL9ewYcN05513atasWSotLQ31aOeNjRs3asGCBXrqqae0fft2vfTSS1q3bp3mzZsX6tEQRFyBgSSpb9++ioiIUF1dnd/2uro6OZ3Orzz2iSee0MKFC/XnP/9ZV1xxRTDH7NY6eg7+8Y9/6ODBgxo3bpxvW3t7uyQpMjJS+/bt08CBA4M7dDdzLn8OEhMT1aNHD0VERPi2DR48WB6PR83NzYqKigrqzN3NuZyD2bNna9KkSfrJT34iSRoyZIhOnjyp7OxszZo1S+Hh/Ld6sDmdzjOeM7vdHpSrLxJXYPD/oqKiNGzYMFVWVvq2tbe3q7KyUm63+0uPKy4u1rx581ReXq7U1NTOGLXb6ug5GDRokHbu3Kna2lrf47vf/a5uuukm1dbWKikpqTPH7xbO5c/BiBEj9MEHH/jiUZLee+89JSYmEi/n4FzOwaeffvqFSDkdlBZ/3V+ncLvdfudMkioqKr7y+8f/LGgfD4ZxVq9ebdlsNqusrMzavXu3lZ2dbcXHx1sej8eyLMuaNGmSlZ+f71u/cOFCKyoqyvrjH/9o/etf//I9jh8/Hqq3YLyOnoPP47eQ/ncdPQeHDh2yYmNjrdzcXGvfvn3W2rVrrYSEBGv+/PmhegvG6+g5mDNnjhUbG2v9/ve/t/bv32+98cYb1sCBA6077rgjVG/BeMePH7d27Nhh7dixw5JkLVq0yNqxY4f14YcfWpZlWfn5+dakSZN860//GvWDDz5o7dmzxyopKeHXqNG5li5davXr18+Kioqyrr32Wuudd97x7bvxxhutrKws39f9+/e3JH3hMWfOnM4fvBvpyDn4PAImMDp6DrZs2WKlpaVZNpvNuvjii63HHnvMam1t7eSpu5eOnIOWlhbrkUcesQYOHGhFR0dbSUlJ1r333mt98sknnT94N/Hmm2+e8d/vp/+5Z2VlWTfeeOMXjhk6dKgVFRVlXXzxxdazzz4b1BnDLIvrawAAwCx8BgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGCc/wNfeqmfyzyc/gAAAABJRU5ErkJggg==","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# distribution of all scores from the beam search\n","plt.hist(all_scores, bins=10)\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0855789e6e6d4b46ab772ab0981f6d27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0949f68ed2914f3a934c2b752efe2a33","IPY_MODEL_6fd097d02ffb41e9892818b3251d79b1","IPY_MODEL_2037c9446fe44ec2a0a75a07569a92d1"],"layout":"IPY_MODEL_f28ed15278c34410b9454befa2ab5f62"}},"0949f68ed2914f3a934c2b752efe2a33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b23800862544f9b8134a9c8227bb9d8","placeholder":"​","style":"IPY_MODEL_dc23efc0a8764f92b53b0c234e59dc73","value":"Downloading readme: 100%"}},"0b6d89eac3f14569950292ed7e84e48c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30ed19096ea242d9928be0665def9670","placeholder":"​","style":"IPY_MODEL_57f1cb96a5f54339a275670023c6e92d","value":"Downloading builder script: 100%"}},"0cf43eb9a66b4947875f6fa2d048100d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c42aca30a614aea988d97d526772966","placeholder":"​","style":"IPY_MODEL_e69251f8823142deb4185d0b8ace1a69","value":" 235M/235M [00:06&lt;00:00, 34.8MB/s]"}},"12c42fce406d48179c57e67d331b38f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b6b2c708f6942b2b4fff7ba98710fda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f9f80af770b452ab24da31b0f965f65":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2037c9446fe44ec2a0a75a07569a92d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84cd5c474c5e4d328b532bb8afb23a85","placeholder":"​","style":"IPY_MODEL_9a3e08fb71784ff499a8d7681f160856","value":" 16.3k/16.3k [00:00&lt;00:00, 395kB/s]"}},"20cf001596f34745ab0a763d1db26f1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af4faa8f35a04b06bf9177dc1889e46e","max":30394,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96fa2fdaa2634d189f2f97dd3dc37a0d","value":30394}},"26678d02176a483e883ce7f5b067b566":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30ed19096ea242d9928be0665def9670":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36b0b74f1f654d6ba951bc8c90fd7c57":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41609760d6d6450bbf8dfc9121550ed4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4511e8136b4b4f389a40eb6894db5aa7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_953645a5b0d34ccf926be03c50b6262f","max":35871,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a59f109308e49a9afafb323119709ef","value":35871}},"4abb98faa57045e6aefbc3674e946140":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_78f2a39ddab249ec9c768b75eb0d2547","max":235072360,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a0a2b843bdb14e76b5a70095ea223d35","value":235072360}},"4b23800862544f9b8134a9c8227bb9d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ce528d014044eb98dd8e2dba47b1918":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51964e8edcb94726b83557bf3b6903c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26678d02176a483e883ce7f5b067b566","placeholder":"​","style":"IPY_MODEL_1b6b2c708f6942b2b4fff7ba98710fda","value":"100%"}},"57f1cb96a5f54339a275670023c6e92d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a03da2908bc459797107ff07227cf8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69ad765cca0b416ea2ab0edb7947e187":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a59f109308e49a9afafb323119709ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e6043451c4b468db3307ff6ef9f65c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6fd097d02ffb41e9892818b3251d79b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ce528d014044eb98dd8e2dba47b1918","max":16258,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f864cbb46b6d4b9799b9c11ba16f6148","value":16258}},"705324651e2d4ae88a16f24fe75ac899":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc81cf6b330047b9b9a723ebcb6cc46e","placeholder":"​","style":"IPY_MODEL_36b0b74f1f654d6ba951bc8c90fd7c57","value":"Downloading: 100%"}},"746d93750bb5448395301b983134ab8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12c42fce406d48179c57e67d331b38f7","placeholder":"​","style":"IPY_MODEL_bc3a369fe78448c7a812c2e676fb06a3","value":" 30.4k/30.4k [00:00&lt;00:00, 944kB/s]"}},"749f1e44cc3b41f5b2e1d1672c9d4e41":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41609760d6d6450bbf8dfc9121550ed4","placeholder":"​","style":"IPY_MODEL_6e6043451c4b468db3307ff6ef9f65c8","value":" 35.9k/35.9k [00:00&lt;00:00, 470kB/s]"}},"78c5a4067d72485b928f6ce8903cb202":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5bc45709da943b0864c91355286338d","placeholder":"​","style":"IPY_MODEL_d6aea1313eb748da8ca524235a011ade","value":"Downloading: 100%"}},"78f2a39ddab249ec9c768b75eb0d2547":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c42aca30a614aea988d97d526772966":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d0864a18b5843b68d28e356fc8f3b5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b64b30bac1244c91af3abaa5bf6c2067","placeholder":"​","style":"IPY_MODEL_5a03da2908bc459797107ff07227cf8c","value":"Downloading metadata: 100%"}},"832ac4efd07f4f42b4ca56562ccecd6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_51964e8edcb94726b83557bf3b6903c6","IPY_MODEL_e92e21a59fff4f3caaf1102f95c03817","IPY_MODEL_9ba9053ed4c5419aa766ca75096a1bb2"],"layout":"IPY_MODEL_93465bf04b7d4119a73a2b12f45e458f"}},"84cd5c474c5e4d328b532bb8afb23a85":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8516b34b01df4fceaa7f378e382f43ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b8d8bb07a8444bbac5b1246059081c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8be8dc909cd34ffcb0bca7189b101dc5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93465bf04b7d4119a73a2b12f45e458f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"953645a5b0d34ccf926be03c50b6262f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96fa2fdaa2634d189f2f97dd3dc37a0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a3e08fb71784ff499a8d7681f160856":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ba9053ed4c5419aa766ca75096a1bb2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8ea82a0e64441218fbb7f72b801a8b0","placeholder":"​","style":"IPY_MODEL_8516b34b01df4fceaa7f378e382f43ee","value":" 1/1 [00:00&lt;00:00, 11.04it/s]"}},"9e18ae6aba9a42a49874bdce6bb00455":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a0a2b843bdb14e76b5a70095ea223d35":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a817346052c04deda9270436aa0f0cda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b6d89eac3f14569950292ed7e84e48c","IPY_MODEL_4511e8136b4b4f389a40eb6894db5aa7","IPY_MODEL_749f1e44cc3b41f5b2e1d1672c9d4e41"],"layout":"IPY_MODEL_a9e38c3233cc4d0b8b4017c327595c28"}},"a9e38c3233cc4d0b8b4017c327595c28":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af4faa8f35a04b06bf9177dc1889e46e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4c61049b41743cc858ea45b0ad16dd4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5bc45709da943b0864c91355286338d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b64b30bac1244c91af3abaa5bf6c2067":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc3a369fe78448c7a812c2e676fb06a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bff22b2d0d1c434499172a2ded4b92be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c5344ad20fd145129a6bbd115b598548":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8f24ddcad8c4616a1dd360d409995c1","max":1660,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bff22b2d0d1c434499172a2ded4b92be","value":1660}},"c92e80687cca4e57a89371ebbe8d1a1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b8d8bb07a8444bbac5b1246059081c3","placeholder":"​","style":"IPY_MODEL_fa170c1739a847248244312e8b23ce17","value":" 1.66k/1.66k [00:00&lt;00:00, 58.1kB/s]"}},"cdb5a1c0ed904c4fba2f64d40b01eb95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78c5a4067d72485b928f6ce8903cb202","IPY_MODEL_4abb98faa57045e6aefbc3674e946140","IPY_MODEL_0cf43eb9a66b4947875f6fa2d048100d"],"layout":"IPY_MODEL_8be8dc909cd34ffcb0bca7189b101dc5"}},"d3d35d3ce0e042c3ac6bafe5e3ff9bc9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_705324651e2d4ae88a16f24fe75ac899","IPY_MODEL_c5344ad20fd145129a6bbd115b598548","IPY_MODEL_c92e80687cca4e57a89371ebbe8d1a1a"],"layout":"IPY_MODEL_69ad765cca0b416ea2ab0edb7947e187"}},"d6aea1313eb748da8ca524235a011ade":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8ea82a0e64441218fbb7f72b801a8b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc23efc0a8764f92b53b0c234e59dc73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e69251f8823142deb4185d0b8ace1a69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8f24ddcad8c4616a1dd360d409995c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e92e21a59fff4f3caaf1102f95c03817":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f9f80af770b452ab24da31b0f965f65","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e18ae6aba9a42a49874bdce6bb00455","value":1}},"f1945a721f604cc98a8ab4e71433eaf7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d0864a18b5843b68d28e356fc8f3b5b","IPY_MODEL_20cf001596f34745ab0a763d1db26f1a","IPY_MODEL_746d93750bb5448395301b983134ab8c"],"layout":"IPY_MODEL_b4c61049b41743cc858ea45b0ad16dd4"}},"f28ed15278c34410b9454befa2ab5f62":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f864cbb46b6d4b9799b9c11ba16f6148":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa170c1739a847248244312e8b23ce17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc81cf6b330047b9b9a723ebcb6cc46e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
